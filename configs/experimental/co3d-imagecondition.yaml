name: "co3d-imagecondition"
tag: "${rmspace:${system.prompt_processor.prompt},_}"
exp_root_dir: "outputs"
seed: 0

data_type: "co3d-datamodule"
data:
  root_dir: ???
  height: 256
  width: 256
  scale_radius: 3.0
  load_preprocessed: false
  cam_scale_factor: 0.95 # inherited from plenoxels
  max_num_frames: 300 # use less frames for debugging
  v2_mode: true
  use_mask: true
  box_crop: true
  box_crop_mask_thr: 0.4
  box_crop_context: 0.1 # The amount of additional padding added to each dimention of the cropping bounding box, relative to vox size.
  train_num_rays: 4096
  train_split: "train"
  val_split: "val"
  test_split: "test"
  render_path: "circle"
  train_views: [0, 50, 100]
  random_camera:
    eval_height: 256
    eval_width: 256
    eval_elevation_deg: 0.
    eval_camera_distance: 1.2
    eval_fovy_deg: 60.

system_type: "image-condition-dreamfusion-system"
system:
  geometry_type: "implicit-volume"
  geometry:
    isosurface_method: "mc-cpu"
    isosurface_resolution: 128
    isosurface_threshold: 0.0
    normal_type: "finite_difference"
    finite_difference_normal_eps: 0.004
    n_feature_dims: 32
    mlp_network_config:
      otype: "VanillaMLP"
      activation: "ReLU"
      output_activation: "none"
      n_neurons: 64
      n_hidden_layers: 2

  material_type: "diffuse-with-point-light-material"
  material:
    diffuse_prob: 1.0
    textureless_prob: 0.2
    ambient_light_color: [1.0, 1.0, 1.0]
    diffuse_light_color: [0.0, 0.0, 0.0]
    ambient_only_steps: ${system.freq.ref_only_steps}

  background_type: "neural-environment-map-background"
  background:
    dir_encoding_config:
      otype: ProgressiveBandFrequency
      n_frequencies: 6
    mlp_network_config:
      otype: VanillaMLP
      n_neurons: 32
      n_hidden_layers: 1
      activation: "ReLU"

  renderer_type: "nerf-volume-renderer"
  renderer:
    num_samples_per_ray: 512

  prompt_processor_type: "stable-diffusion-prompt-processor"
  prompt_processor:
    pretrained_model_name_or_path: "runwayml/stable-diffusion-v1-5"
    prompt: ???

  guidance_type: "stable-diffusion-guidance"
  guidance:
    pretrained_model_name_or_path: "runwayml/stable-diffusion-v1-5"
    guidance_scale: 100.
    weighting_strategy: sds

  freq:
    n_ref: 2
    ref_only_steps: 1000

  loggers:
    wandb:
      enable: false
      project: 'threestudio'
      name: None

  loss:
    lambda_sds: 0.1
    lambda_rgb: 10.
    lambda_mask: 1.
    lambda_depth: 0.
    # lambda_depth: [0.0, 0.0, 1.0, 10000]
    lambda_normal_smooth: 0.0
    lambda_orient: 1.0
    # lambda_orient: [1000, 0.0, 10, 6000]
    lambda_sparsity: 0.0
    lambda_opaque: 0.01
  optimizer:
    name: Adan
    args:
      eps: 1.0e-8
      weight_decay: 2.0e-5
      max_grad_norm: 5.0
      foreach: False
    params:
      geometry.encoding:
        lr: 0.05
      geometry.network:
        lr: 0.005
      background.network:
        lr: 0.005

trainer:
  max_steps: 10000
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  val_check_interval: 500
  limit_val_batches: 6
  enable_progress_bar: true
  precision: 16-mixed

checkpoint:
  save_last: true # save at each validation time
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}
